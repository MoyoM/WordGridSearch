{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import ascii_uppercase, ascii_lowercase\n",
    "from random import choice\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### functions for generating a set o K words that whose sum of letters adds up to a given sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_sub_vect(vect, n, sum):\n",
    "    \"\"\"\n",
    "    This function produces a subarray whose elements add up to a given sum (sum).\n",
    "    vect = 1-D Array with n samples, inflated number, to choose subset from.\n",
    "    n = number of elements in full array to choose from, 50 is default.\n",
    "    sum = sum to achieve in subset selected.     \n",
    "    \"\"\"\n",
    "     \n",
    "    curr_sum = vect[0]\n",
    "    start = 0\n",
    " \n",
    "    i = 1\n",
    "    while i <= n:\n",
    "        \n",
    "        while curr_sum  < sum:\n",
    "            curr_sum = curr_sum + vect[i]\n",
    "            i += 1\n",
    "    \n",
    "        if curr_sum == sum:\n",
    "            return vect[start:i]\n",
    "        else:\n",
    "            curr_sum = curr_sum - vect[start]\n",
    "            start += 1\n",
    "         \n",
    "    if i  == n & curr_sum != sum:\n",
    "        return(\"No subarray found, increase sample size N\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_set(weights, n, sum):\n",
    "    \"\"\"\n",
    "    This function selects the best subset that includes at least onof each unique element.\n",
    "    weights = length of each word to choose from.\n",
    "    In this algorithm n elements of given weights are sampled randomly over 10 times\n",
    "    and the best subset is sought.\n",
    "    sum = sum to be achieved in subset.\n",
    "    n = number of elements to choose from, default, n=50\n",
    "    \"\"\"\n",
    "\n",
    "    for iter in range(10):\n",
    "        vect=np.random.choice(weights, n)\n",
    "        out_set= len(set(sum_sub_vect(vect=vect,n=n, sum=sum)))\n",
    "    \n",
    "        if out_set == len(weights):\n",
    "            break\n",
    "    \n",
    "    return sum_sub_vect(vect=vect,n=n, sum=sum)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words(word_dict, n, N, x, weights=[]):\n",
    "    \"\"\"\n",
    "    This function finds the matching words to the best subset of word lengths sampled.\n",
    "    word_dict = keys are the words, values are count of letters in each word (weights)\n",
    "    n = sample size large enough to sample from to get subarray with sum weights equivalent required word density(x)\n",
    "    N = Grid size N*N , e.g. for 12^12 grid N is 12\n",
    "    weights = 1-D array of number of letters in each word\n",
    "    \"\"\"\n",
    "    sum = math.ceil(N*x)\n",
    "    out_values=best_set(weights=weights,n=n,sum=sum)\n",
    "    words_out = []\n",
    "    for i in range(len(out_values)):\n",
    "        words_out.append(list(word_dict.keys())[list(word_dict.values()).index(out_values[i])])\n",
    "    return words_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_out(file_path):\n",
    "    \"\"\" This writes out words \"\"\"\n",
    "    with open(file_path,'w') as file:\n",
    "        for item in words_for_grid:\n",
    "            file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7, 7, 7, 5, 7, 3, 7, 5, 3, 7, 4, 4, 5, 5, 5, 5, 5, 7, 4, 7, 5, 3,\n",
       "       7, 7, 7, 5, 3, 4, 7, 5, 7, 5, 7, 3, 5, 7, 5, 5, 5, 5, 5, 5, 7, 7, 7,\n",
       "       5, 7, 7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.random.choice([4,5,7,5,3],50, p=[0.1, 0.2, 0.3, 0.2, 0.2])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 3, 7, 5, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_sub_vect(test,50, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_values=best_set(weights=[5,3,7], n=50, sum=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 3, 7, 3, 7])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGE 1 SOLUTION \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of a list of words that occupy  25%  (x%) of Grid.\n",
    "-------------------------------------------------------------\n",
    "25% of a 12X12 Grid is 36. \n",
    "A set of words that add to 36 words letters were selected using 'sum_sub_vector', 'best_set' and 'get_words' methods in this module.\n",
    "\n",
    "Summary of solution\n",
    "-------------------\n",
    "A set of words that give this sum of letters equivalent to x% f grid is generated.\n",
    "The best is selected as the set that contains at least on of each word.\n",
    "Possible limitations and extensions to the approach I used are:\n",
    "a) I chose a words with unique lengths and used length size to identify the frequency of\n",
    "the given words by matching the lengths in an array of lengths that adds up to N*x%, the required\n",
    "word density.\n",
    "If a set of different words with same length are chosen, in this current code, this may lead to problems\n",
    "identifying which words where chosen to satisfy the Word Density constraint.\n",
    "However any words matching the length requirements can still be used. Alternatively a method to place words \n",
    "with same length with different probabilities can be employed. This will be one among other posible solutions depending on use case needs for the project.\n",
    "b) At some point x%, the Word Density, may not be accomodated as there may not be enough empty spaces in the grid to\n",
    "fill with chosen words. At this time the limit in empty spaces in Grid as x% tends to increase to 100% has not been explored.\n",
    "One possible solution will be to create an exception in the algorithm for adding words when no empty spaces are available for chosen words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_for_grid = get_words(word_dict = {'HOUSE':5,'DOG':3, 'KITCHEN':7}, weights=[5,3,7], n=50, N=144, x=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HOUSE', 'DOG', 'DOG', 'KITCHEN', 'DOG', 'DOG', 'HOUSE', 'KITCHEN']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_for_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_out(\"words_for_grid_at_density_x.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test that the word set produced has 36 letters to fill 25% Grid as designed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.25*144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters=0\n",
    "for letter in ''.join(words_for_grid):\n",
    "    letters +=1\n",
    "letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare python script to import into other modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook word_list_generation.ipynb to script\n",
      "[NbConvertApp] Writing 5044 bytes to word_list_generation.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script word_list_generation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
